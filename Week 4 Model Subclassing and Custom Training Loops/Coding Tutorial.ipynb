{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model subclassing and custom training loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Coding tutorials\n",
    " #### [1. Model subclassing](#coding_tutorial_1)\n",
    " #### [2. Custom layers](#coding_tutorial_2)\n",
    " #### [3. Automatic differentiation](#coding_tutorial_3)\n",
    " #### [4. Custom training loops](#coding_tutorial_4)\n",
    " #### [5. tf.function decorator](#coding_tutorial_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_1\"></a>\n",
    "## Model subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Softmax, concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple model using the model subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "\n",
    "class MyModel(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dense2 = Dense(10)\n",
    "        self.dense3 = Dense(5)\n",
    "        self.softmax = Softmax()\n",
    "        #self.dropout = Dropout(0.5)\n",
    "        \n",
    "    def call(self, inputs, Training=True):\n",
    "        x = self.dense1(inputs)\n",
    "        y1 = self.dense2(inputs)\n",
    "        y2 = self.dense3(y1)\n",
    "        concat = concatenate([x,y2])\n",
    "#         if Training:\n",
    "#             x = self.dropout(x)\n",
    "\n",
    "        return self.softmax(concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              multiple                  704       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              multiple                  110       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              multiple                  55        \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 869\n",
      "Trainable params: 869\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print the model summary\n",
    "\n",
    "model = MyModel()\n",
    "model(tf.random.uniform([1,10]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_2\"></a>\n",
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        \n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units), initializer='zeros')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.076607   -0.00956125  0.0631026 ]], shape=(1, 3), dtype=float32)\n",
      "[<tf.Variable 'Variable:0' shape=(5, 3) dtype=float32, numpy=\n",
      "array([[ 0.03864897, -0.03158235,  0.06690072],\n",
      "       [-0.15041804,  0.04570355, -0.05178002],\n",
      "       [ 0.04873775, -0.05855143,  0.11001752],\n",
      "       [-0.05093267, -0.02183552, -0.03929253],\n",
      "       [ 0.03735699,  0.0567045 , -0.02274309]], dtype=float32)>, <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "dense_layer = MyLayer(3, 5)\n",
    "x = tf.ones((1,5))\n",
    "\n",
    "print(dense_layer(x))\n",
    "print(dense_layer.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify trainable weights\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayer, self).__init__()\n",
    "        \n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal', trainable=False)\n",
    "        self.b = self.add_weight(shape=(units), initializer='zeros')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "dense_layer = MyLayer(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable weights: 1\n",
      "non-trainable weights: 1\n"
     ]
    }
   ],
   "source": [
    "print('trainable weights:', len(dense_layer.trainable_weights))\n",
    "print('non-trainable weights:', len(dense_layer.non_trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom layer to accumulate means of output values\n",
    "\n",
    "class MyLayerMean(Layer):\n",
    "    \n",
    "    def __init__(self, units, input_dim):\n",
    "        super(MyLayerMean, self).__init__()\n",
    "        \n",
    "        self.w = self.add_weight(shape=(input_dim, units), initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(units), initializer='zeros')\n",
    "        self.sum_activation = tf.Variable(initial_value=tf.zeros((units,)), trainable=False)\n",
    "        self.number_of_times_called = tf.Variable(initial_value=0, trainable=False)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        activations = tf.matmul(inputs, self.w) + self.b\n",
    "        self.sum_activation.assign_add(tf.reduce_sum(activations, axis=0))\n",
    "        self.number_of_times_called.assign_add(inputs.shape[0])\n",
    "        \n",
    "        return activations, self.sum_activation/tf.cast(self.number_of_times_called, tf.float32)\n",
    "\n",
    "dense_layer = MyLayerMean(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10821151  0.09168078  0.00371452]\n",
      "[-0.10821151  0.09168078  0.00371452]\n"
     ]
    }
   ],
   "source": [
    "# Test the layer\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((2, 5)))\n",
    "print(activation_means.numpy())\n",
    "\n",
    "y, activation_means = dense_layer(tf.ones((25, 5)))\n",
    "print(activation_means.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dropout layer as a custom layer\n",
    "\n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, self.rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement the custom layers into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model using custom layers with the model subclassing API\n",
    "\n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, input_dim_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = MyLayer(units_1, input_dim_1)\n",
    "        self.do1 = MyDropout(0.5)\n",
    "        self.fc2 = MyLayer(units_2, units_1)\n",
    "        self.do2 = MyDropout(0.5)\n",
    "        self.fc3 = MyLayer(units_3, units_2)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.0069214  0.02376164 0.00765234 0.00897997 0.02400807 0.02655453\n",
      "  0.01470018 0.01380537 0.00909741 0.00946805 0.03031897 0.05255055\n",
      "  0.00804285 0.07187328 0.01164568 0.00899165 0.01150675 0.01172656\n",
      "  0.0093837  0.01070452 0.02787809 0.01325259 0.01747757 0.01285255\n",
      "  0.04323637 0.00950964 0.00677221 0.03577766 0.02471427 0.06167721\n",
      "  0.0044905  0.04209806 0.04051574 0.00325791 0.05219585 0.01466668\n",
      "  0.02039598 0.00980926 0.01119609 0.01316375 0.00640665 0.07552409\n",
      "  0.01528005 0.01959507 0.02083821 0.02572445]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_5 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout (MyDropout)       multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_6 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_1 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_7 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 174\n",
      "Non-trainable params: 647,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a model object\n",
    "\n",
    "model = MyModel(64,10000,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_3\"></a>\n",
    "## Automatic differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0a4266bf98>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create data from a noise contaminated linear model\n",
    "\n",
    "def MakeNoisyData(m, b, n=20):\n",
    "    x = tf.random.uniform(shape=(n,))\n",
    "    noise = tf.random.normal(shape=(len(x),), stddev=0.1)\n",
    "    y = m * x + b + noise\n",
    "    return x, y\n",
    "\n",
    "m=1\n",
    "b=2\n",
    "x_train, y_train = MakeNoisyData(m,b)\n",
    "plt.plot(x_train, y_train, 'b.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a custom layer for the linear regression model\n",
    "\n",
    "class LinearLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.m = self.add_weight(shape=(1,), initializer='random_normal')\n",
    "        self.b = self.add_weight(shape=(1,), initializer='random_normal')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.m * inputs + self.b\n",
    "    \n",
    "linear_regression = LinearLayer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss 6.2821264\n"
     ]
    }
   ],
   "source": [
    "# Define the mean squared error loss function\n",
    "\n",
    "def SquaredError(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) \n",
    "\n",
    "starting_loss = SquaredError(linear_regression(x_train), y_train)\n",
    "print(\"Starting loss\", starting_loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1 : 5.374980926513672\n",
      "Loss after epoch 2 : 4.070504188537598\n",
      "Loss after epoch 3 : 3.083034038543701\n",
      "Loss after epoch 4 : 2.3355326652526855\n",
      "Loss after epoch 5 : 1.769684076309204\n",
      "Loss after epoch 6 : 1.341343641281128\n",
      "Loss after epoch 7 : 1.0170947313308716\n",
      "Loss after epoch 8 : 0.7716414928436279\n",
      "Loss after epoch 9 : 0.5858351588249207\n",
      "Loss after epoch 10 : 0.4451807141304016\n",
      "Loss after epoch 11 : 0.33870548009872437\n",
      "Loss after epoch 12 : 0.25810348987579346\n",
      "Loss after epoch 13 : 0.1970871388912201\n",
      "Loss after epoch 14 : 0.15089678764343262\n",
      "Loss after epoch 15 : 0.1159295067191124\n",
      "Loss after epoch 16 : 0.08945782482624054\n",
      "Loss after epoch 17 : 0.06941728293895721\n",
      "Loss after epoch 18 : 0.05424501374363899\n",
      "Loss after epoch 19 : 0.04275797680020332\n",
      "Loss after epoch 20 : 0.03406059369444847\n",
      "Loss after epoch 21 : 0.027474969625473022\n",
      "Loss after epoch 22 : 0.022487901151180267\n",
      "Loss after epoch 23 : 0.018710941076278687\n",
      "Loss after epoch 24 : 0.01585003361105919\n",
      "Loss after epoch 25 : 0.013682568445801735\n",
      "Loss after epoch 26 : 0.01204005628824234\n",
      "Loss after epoch 27 : 0.010794905945658684\n",
      "Loss after epoch 28 : 0.00985060166567564\n",
      "Loss after epoch 29 : 0.009134016931056976\n",
      "Loss after epoch 30 : 0.008589835837483406\n"
     ]
    }
   ],
   "source": [
    "# Implement a gradient descent training loop for the linear regression model\n",
    "\n",
    "steps = 30\n",
    "lr = 0.05\n",
    "\n",
    "for i in range(steps):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        \n",
    "        predictions = linear_regression(x_train)\n",
    "        loss = SquaredError(predictions, y_train)\n",
    "        \n",
    "    gradients = tape.gradient(loss, linear_regression.trainable_weights)\n",
    "        \n",
    "    linear_regression.m.assign_sub(lr * gradients[0])\n",
    "    linear_regression.b.assign_sub(lr * gradients[1])\n",
    "    print(f\"Loss after epoch {i+1} : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m:1,  trained m:[1.0396515]\n",
      "b:2,  trained b:[1.9281613]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f097c0c7710>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned regression model\n",
    "\n",
    "print(\"m:{},  trained m:{}\".format(m,linear_regression.m.numpy()))\n",
    "print(\"b:{},  trained b:{}\".format(b,linear_regression.b.numpy()))\n",
    "\n",
    "plt.plot(x_train, y_train, 'b.')\n",
    "\n",
    "x_linear_regression=np.linspace(min(x_train), max(x_train),50)\n",
    "plt.plot(x_linear_regression, linear_regression.m*x_linear_regression+linear_regression.b, 'r.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_4\"></a>\n",
    "## Custom training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.01578664 0.00857779 0.02634911 0.03754414 0.01169619 0.02595064\n",
      "  0.02463659 0.02443359 0.01847834 0.03965329 0.00906289 0.02003738\n",
      "  0.00992668 0.00864463 0.01358816 0.08443103 0.0126432  0.01175363\n",
      "  0.02405392 0.04818554 0.04128646 0.01532383 0.04037536 0.02131099\n",
      "  0.00390778 0.00996401 0.01648767 0.00679411 0.06894042 0.00674838\n",
      "  0.0315888  0.01791004 0.00694038 0.0351826  0.01490395 0.01277871\n",
      "  0.01719942 0.02656671 0.02953229 0.01615123 0.01191233 0.01574645\n",
      "  0.00963369 0.02665044 0.00846419 0.01226634]], shape=(1, 46), dtype=float32)\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_layer_3 (MyLayer)         multiple                  640064    \n",
      "_________________________________________________________________\n",
      "my_dropout_2 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_4 (MyLayer)         multiple                  4160      \n",
      "_________________________________________________________________\n",
      "my_dropout_3 (MyDropout)     multiple                  0         \n",
      "_________________________________________________________________\n",
      "my_layer_5 (MyLayer)         multiple                  2990      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units), initializer='zeros', name='bias')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = MyLayer(units_1)\n",
    "        self.do1 = MyDropout(0.5)\n",
    "        self.fc2 = MyLayer(units_2)\n",
    "        self.do2 = MyDropout(0.5)\n",
    "        self.fc3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return self.softmax(x)\n",
    "    \n",
    "model = MyModel(64,64,46)\n",
    "print(model(tf.ones((1, 10000))))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the reuters dataset and define the class_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "class_names = ['cocoa','grain','veg-oil','earn','acq','wheat','copper','housing','money-supply',\n",
    "   'coffee','sugar','trade','reserves','ship','cotton','carcass','crude','nat-gas',\n",
    "   'cpi','money-fx','interest','gnp','meal-feed','alum','oilseed','gold','tin',\n",
    "   'strategic-metal','livestock','retail','ipi','iron-steel','rubber','heat','jobs',\n",
    "   'lei','bop','zinc','orange','pet-chem','dlr','gas','silver','wpi','hog','lead']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (8982,)\n",
      "Train labels shape: (8982,)\n",
      "Test data shape: (2246,)\n",
      "Test labels shape: (2246,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data shape: {train_data.shape}\")\n",
    "print(f\"Train labels shape: {train_labels.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")\n",
    "print(f\"Test labels shape: {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Print the class of the first sample\n",
    "\n",
    "print(\"Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the Reuters word index\n",
    "\n",
    "word_to_index = reuters.get_word_index()\n",
    "\n",
    "invert_word_index = dict([(value, key) for (key, value) in word_to_index.items()])\n",
    "text_news = ' '.join([invert_word_index.get(i - 3, '?') for i in train_data[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first data example sentence\n",
    "\n",
    "text_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (8982, 10000)\n",
      "Shape of x_test: (2246, 10000)\n"
     ]
    }
   ],
   "source": [
    "# Define a function that encodes the data into a 'bag of words' representation\n",
    "\n",
    "def bag_of_words(text_samples, elements=10000):\n",
    "    output = np.zeros((len(text_samples), elements))\n",
    "    for i, word in enumerate(text_samples):\n",
    "        output[i, word] = 1.\n",
    "    return output\n",
    "\n",
    "x_train = bag_of_words(train_data)\n",
    "x_test = bag_of_words(test_data)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the loss function and optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categorical cross entropy loss and Adam optimizer\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "def loss(model, x, y, wd):\n",
    "    kernel_variables = []\n",
    "    for l in model.layers:\n",
    "        for w in l.weights:\n",
    "            if 'kernel' in w.name:\n",
    "                kernel_variables.append(w)\n",
    "    wd_penalty = wd * tf.reduce_sum([tf.reduce_sum(tf.square(k)) for k in kernel_variables])\n",
    "    y_ = model(x)\n",
    "    return loss_object(y_true=y, y_pred=y_) + wd_penalty\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the forward and backward pass\n",
    "\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Loss: 3.259  Accuracy: 49.91%\n",
      "Epoch: 2  Loss: 1.885  Accuracy: 63.04%\n",
      "Epoch: 3  Loss: 1.811  Accuracy: 66.46%\n",
      "Epoch: 4  Loss: 1.754  Accuracy: 67.85%\n",
      "Epoch: 5  Loss: 1.752  Accuracy: 68.56%\n",
      "Epoch: 6  Loss: 1.741  Accuracy: 68.64%\n",
      "Epoch: 7  Loss: 1.718  Accuracy: 69.39%\n",
      "Epoch: 8  Loss: 1.718  Accuracy: 69.78%\n",
      "Epoch: 9  Loss: 1.705  Accuracy: 70.21%\n",
      "Epoch: 10  Loss: 1.716  Accuracy: 70.63%\n",
      "Duration :231.637\n"
     ]
    }
   ],
   "source": [
    "# Implement the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))    \n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_average = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy_average = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x,y in train_dataset:\n",
    "        curr_loss, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        epoch_loss_average(curr_loss)\n",
    "        epoch_accuracy_average(to_categorical(y), model(x))\n",
    "    \n",
    "    train_loss_results.append(epoch_loss_average.result())\n",
    "    train_accuracy_results.append(epoch_accuracy_average.result())\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}  Loss: {epoch_loss_average.result():.3f}  Accuracy: {epoch_accuracy_average.result():.2%}\")\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dataset object for the test set\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, test_labels))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect average loss and accuracy\n",
    "\n",
    "epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.849\n",
      "Test accuracy: 67.008%\n"
     ]
    }
   ],
   "source": [
    "# Loop over the test set and print scores\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value = loss(model, x, y, weight_decay)    \n",
    "    # Compute current loss\n",
    "    epoch_loss_avg(loss_value)  \n",
    "    # Compare predicted label to actual label\n",
    "    epoch_accuracy(to_categorical(y), model(x))\n",
    "\n",
    "print(\"Test loss: {:.3f}\".format(epoch_loss_avg.result().numpy()))\n",
    "print(\"Test accuracy: {:.3%}\".format(epoch_accuracy.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training loss and accuracy\n",
    "\n",
    "fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\n",
    "fig.suptitle('Training Metrics')\n",
    "\n",
    "axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "axes[0].plot(train_loss_results)\n",
    "\n",
    "axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "axes[1].plot(train_accuracy_results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: earn\n",
      "     Label: earn\n"
     ]
    }
   ],
   "source": [
    "# Get the model prediction for an example input\n",
    "\n",
    "predicted_label = np.argmax(model(x_train[np.newaxis,0]),axis=1)[0]\n",
    "print(\"Prediction: {}\".format(class_names[predicted_label]))\n",
    "print(\"     Label: {}\".format(class_names[train_labels[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"coding_tutorial_5\"></a>\n",
    "## tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import reuters\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new model\n",
    "\n",
    "# Define the custom layers and model\n",
    "\n",
    "class MyLayer(Layer):\n",
    "    \n",
    "    def __init__(self, units):\n",
    "        super(MyLayer, self).__init__()\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units), initializer='random_normal', name='kernel')\n",
    "        self.b = self.add_weight(shape=(self.units), initializer='zeros', name='bias')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b\n",
    "    \n",
    "class MyDropout(Layer):\n",
    "\n",
    "    def __init__(self, rate):\n",
    "        super(MyDropout, self).__init__()\n",
    "        self.rate = rate\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass for dropout layer\n",
    "        return tf.nn.dropout(inputs, self.rate)\n",
    "    \n",
    "class MyModel(Model):\n",
    "\n",
    "    def __init__(self, units_1, units_2, units_3):\n",
    "        super(MyModel, self).__init__()\n",
    "        # Define layers\n",
    "        self.fc1 = MyLayer(units_1)\n",
    "        self.do1 = MyDropout(0.5)\n",
    "        self.fc2 = MyLayer(units_2)\n",
    "        self.do2 = MyDropout(0.5)\n",
    "        self.fc3 = MyLayer(units_3)\n",
    "        self.softmax = Softmax()\n",
    "           \n",
    "    def call(self, inputs):\n",
    "        # Define forward pass\n",
    "        x = self.fc1(inputs)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.do2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "       \n",
    "        return self.softmax(x)\n",
    "    \n",
    "model = MyModel(64,64,46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefine the grad function using the @tf.function decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the @tf.function decorator\n",
    "\n",
    "@tf.function\n",
    "def grad(model, inputs, targets, wd):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, wd)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer my_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch: 1  Loss: 3.307  Accuracy: 49.08%\n",
      "Epoch: 2  Loss: 1.919  Accuracy: 61.00%\n",
      "Epoch: 3  Loss: 1.849  Accuracy: 65.39%\n",
      "Epoch: 4  Loss: 1.796  Accuracy: 67.96%\n",
      "Epoch: 5  Loss: 1.758  Accuracy: 68.92%\n",
      "Epoch: 6  Loss: 1.733  Accuracy: 69.54%\n",
      "Epoch: 7  Loss: 1.721  Accuracy: 70.06%\n",
      "Epoch: 8  Loss: 1.717  Accuracy: 70.50%\n",
      "Epoch: 9  Loss: 1.707  Accuracy: 70.51%\n",
      "Epoch: 10  Loss: 1.710  Accuracy: 70.92%\n",
      "Duration :204.959\n"
     ]
    }
   ],
   "source": [
    "# Re-run the training loop\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, train_labels))    \n",
    "train_dataset = train_dataset.batch(32)\n",
    "\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 10\n",
    "weight_decay = 0.005\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss_average = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy_average = tf.keras.metrics.CategoricalAccuracy()\n",
    "    \n",
    "    for x,y in train_dataset:\n",
    "        curr_loss, grads = grad(model, x, y, weight_decay)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        epoch_loss_average(curr_loss)\n",
    "        epoch_accuracy_average(to_categorical(y), model(x))\n",
    "    \n",
    "    train_loss_results.append(epoch_loss_average.result())\n",
    "    train_accuracy_results.append(epoch_accuracy_average.result())\n",
    "    \n",
    "    print(f\"Epoch: {epoch+1}  Loss: {epoch_loss_average.result():.3f}  Accuracy: {epoch_accuracy_average.result():.2%}\")\n",
    "    \n",
    "print(\"Duration :{:.3f}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print the autograph code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def tf__grad(model, inputs, targets, wd):\n",
      "  do_return = False\n",
      "  retval_ = ag__.UndefinedReturnValue()\n",
      "  with ag__.FunctionScope('grad', 'grad_scope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as grad_scope:\n",
      "    with tf.GradientTape() as tape:\n",
      "      loss_value = ag__.converted_call(loss, grad_scope.callopts, (model, inputs, targets, wd), None, grad_scope)\n",
      "    do_return = True\n",
      "    retval_ = grad_scope.mark_return_value((loss_value, ag__.converted_call(tape.gradient, grad_scope.callopts, (loss_value, model.trainable_variables), None, grad_scope)))\n",
      "  do_return,\n",
      "  return ag__.retval(retval_)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use tf.autograph.to_code to see the generated code\n",
    "\n",
    "print(tf.autograph.to_code(grad.python_function))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
